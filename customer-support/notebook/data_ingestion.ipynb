{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4806da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e8b447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaIndex core\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    Document,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "65c77b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes & postprocessors\n",
    "from llama_index.core.schema import TextNode, NodeWithScore\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f03b6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# BM25\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Data\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\", \"maktek_faqs\")\n",
    "EMBED_MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
    "RERANK_MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "K = 5  # weâ€™ll evaluate @5 as requested\n",
    "# knobs\n",
    "VEC_TOP_K = max(12, K)      # gather more for better recall\n",
    "BM25_TOP_K = max(12, K)\n",
    "RERANK_TOP_N = max(8, K)\n",
    "FINAL_TOP_N = K  \n",
    "\n",
    "# Optional LLM\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "LLM_TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b851a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CorpusItem:\n",
    "    doc_id: str\n",
    "    text: str\n",
    "    metadata: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0344f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# DATA LOADING\n",
    "# -----------------------------\n",
    "def load_maktek_dataset() -> List[Document]:\n",
    "    #ds = load_dataset(\"MakTek/Customer_support_faqs_dataset\", split=\"train\")\n",
    "    df = pd.read_json(\"hf://datasets/MakTek/Customer_support_faqs_dataset/train_expanded.json\", lines=True)\n",
    "    df = df.drop_duplicates(subset=\"question\")\n",
    "    df.insert(0,'id',df.index)\n",
    "    df.to_csv(\"../data/data.csv\",index=False)\n",
    "    df_dict = df.to_dict(orient='records')\n",
    "    docs: List[Document] = []\n",
    "    for i, row in enumerate(df_dict):\n",
    "        q = (row.get(\"question\") or \"\").strip()\n",
    "        a = (row.get(\"answer\") or \"\").strip()\n",
    "        doc_id = f\"faq-{i:04d}\"\n",
    "        text = f\"Q: {q}\\n\\nA: {a}\"\n",
    "        metadata = {\"question\": q, \"answer\": a, \"source\": \"MakTek\", \"doc_id\": doc_id}\n",
    "        docs.append(Document(text=text, metadata=metadata, doc_id=doc_id))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "839d0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# INDEX & BM25 BUILD\n",
    "# -----------------------------\n",
    "def build_index(docs: List[Document]) -> VectorStoreIndex:\n",
    "    Settings.embed_model = HuggingFaceEmbedding(model_name=EMBED_MODEL_NAME)\n",
    "    client = QdrantClient(url=QDRANT_URL)\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=QDRANT_COLLECTION)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(docs, storage_context=storage_context, show_progress=True)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(s: str) -> List[str]:\n",
    "    return s.lower().split()\n",
    "\n",
    "\n",
    "def build_bm25_corpus(docs: List[Document]) -> Tuple[BM25Okapi, Dict[str, CorpusItem]]:\n",
    "    corpus_items: Dict[str, CorpusItem] = {}\n",
    "    tokenized_corpus = []\n",
    "    for d in docs:\n",
    "        doc_id = d.doc_id or d.metadata.get(\"doc_id\")\n",
    "        corpus_items[doc_id] = CorpusItem(doc_id=doc_id, text=d.text, metadata=d.metadata)\n",
    "        tokenized_corpus.append(simple_tokenize(d.text))\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    return bm25, corpus_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460691e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# RETRIEVAL HELPERS\n",
    "# -----------------------------\n",
    "def bm25_retrieve(bm25: BM25Okapi, corpus_items: Dict[str, CorpusItem], query: str, top_k: int) -> List[NodeWithScore]:\n",
    "    scores = bm25.get_scores(simple_tokenize(query))\n",
    "    ranked = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    doc_ids = list(corpus_items.keys())\n",
    "    results: List[NodeWithScore] = []\n",
    "    for idx, sc in ranked:\n",
    "        doc_id = doc_ids[idx]\n",
    "        item = corpus_items[doc_id]\n",
    "        node = TextNode(id_=doc_id, text=item.text, metadata=item.metadata)\n",
    "        results.append(NodeWithScore(node=node, score=float(sc)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "585cdc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_retrieve(index: VectorStoreIndex, query: str, top_k: int) -> List[NodeWithScore]:\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    return retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a687211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_candidates(vec_nodes: List[NodeWithScore], bm25_nodes: List[NodeWithScore]) -> List[NodeWithScore]:\n",
    "    \"\"\"\n",
    "    âœ… Fix: merge by stable metadata['doc_id'] to remove duplicates from vector + BM25.\n",
    "    \"\"\"\n",
    "    merged: Dict[str, NodeWithScore] = {}\n",
    "    for n in vec_nodes + bm25_nodes:\n",
    "        meta_doc_id = n.metadata.get(\"doc_id\") if n.metadata else n.node.node_id\n",
    "        if meta_doc_id not in merged or merged[meta_doc_id].score < n.score:\n",
    "            merged[meta_doc_id] = n\n",
    "    return list(merged.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "45eac5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_deduplicate(results: List[NodeWithScore], top_n: int = FINAL_TOP_N) -> List[NodeWithScore]:\n",
    "    \"\"\"\n",
    "    âœ… Deduplicate only by *exact question text*.\n",
    "    Removes repeated identical questions but keeps paraphrased versions.\n",
    "    \"\"\"\n",
    "    seen_questions = set()\n",
    "    deduped: List[NodeWithScore] = []\n",
    "\n",
    "    for node in results:\n",
    "        question = (node.metadata.get(\"question\") or \"\").strip().lower()\n",
    "        if question not in seen_questions:\n",
    "            seen_questions.add(question)\n",
    "            deduped.append(node)\n",
    "        if len(deduped) >= top_n:\n",
    "            break\n",
    "\n",
    "    return deduped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b15e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reranker() -> SentenceTransformerRerank:\n",
    "    \"\"\"\n",
    "    âœ… Centralized reranker builder.\n",
    "    Useful if you want to change reranker models or parameters in one place.\n",
    "    \"\"\"\n",
    "    return SentenceTransformerRerank(\n",
    "        model=RERANK_MODEL_NAME,\n",
    "        top_n=RERANK_TOP_N,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f0742a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# MAIN QUERY METHODS\n",
    "# -----------------------------\n",
    "def query_without_llm(index: VectorStoreIndex, bm25: BM25Okapi, corpus_items: Dict[str, CorpusItem], query: str) -> List[Dict]:\n",
    "    vec_nodes = vector_retrieve(index, query, VEC_TOP_K)\n",
    "    bm25_nodes = bm25_retrieve(bm25, corpus_items, query, BM25_TOP_K)\n",
    "    merged = merge_candidates(vec_nodes, bm25_nodes)\n",
    "\n",
    "    reranker = build_reranker()\n",
    "    reranked = reranker.postprocess_nodes(merged, query_str=query)\n",
    "\n",
    "    deduped = semantic_deduplicate(reranked, top_n=FINAL_TOP_N)\n",
    "\n",
    "    results = []\n",
    "    for n in deduped:\n",
    "        results.append({\n",
    "            \"doc_id\": n.metadata.get(\"doc_id\"),\n",
    "            \"question\": n.metadata.get(\"question\"),\n",
    "            \"answer\": n.metadata.get(\"answer\"),\n",
    "            \"score\": n.score\n",
    "        })\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_llm(index: VectorStoreIndex, bm25: BM25Okapi, corpus_items: Dict[str, CorpusItem], query: str) -> Dict:\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise RuntimeError(\"OPENAI_API_KEY is not set.\")\n",
    "\n",
    "    top_ctx = query_without_llm(index, bm25, corpus_items, query)\n",
    "    context_text = \"\\n\\n\".join([f\"[{i+1}] Q: {c['question']}\\nA: {c['answer']}\" for i, c in enumerate(top_ctx)])\n",
    "\n",
    "    prompt = f\"\"\"You are a helpful support assistant. Answer the user's question using ONLY the context below.\n",
    "If the answer is not present, say you don't have enough information.\n",
    "\n",
    "User question:\n",
    "{query}\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Return a concise, direct answer.\n",
    "\"\"\"\n",
    "\n",
    "    llm = OpenAI(model=OPENAI_MODEL, temperature=LLM_TEMPERATURE)\n",
    "    completion = llm.complete(prompt)\n",
    "    return {\"query\": query, \"answer\": completion.text.strip(), \"top_context\": top_ctx}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1fd86820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading MakTek dataset...\n",
      "Loaded 89 FAQ entries.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“¥ Loading MakTek dataset...\")\n",
    "docs = load_maktek_dataset()\n",
    "print(f\"Loaded {len(docs)} FAQ entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d5e01c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Building vector index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5206c809f280466a89257a1fab65b9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2407bf6c721465d92f473504d65adb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"ðŸ“Š Building vector index...\")\n",
    "index = build_index(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "19016014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BM25 over the same corpus ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Building BM25 over the same corpus ...\")\n",
    "bm25, corpus_items = build_bm25_corpus(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f686b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Retrieval-Only ===\n",
      "\n",
      "Q: How do I reset my password?\n",
      "  1. [faq-0109] How can I reset my password? (score=10.1189)\n",
      "\n",
      "Q: Do you offer international shipping?\n",
      "  1. [faq-0006] Do you offer international shipping? (score=10.9858)\n",
      "  2. [faq-0033] Can I order a product for delivery to a different country? (score=9.1520)\n",
      "  3. [faq-0022] Do you offer expedited shipping? (score=2.7228)\n",
      "  4. [faq-0017] Do you offer bulk or wholesale discounts? (score=-4.5605)\n",
      "  5. [faq-0085] Do you offer a satisfaction guarantee? (score=-7.7589)\n",
      "\n",
      "Q: What is your refund policy?\n",
      "  1. [faq-0003] What is your return policy? (score=6.4888)\n",
      "  2. [faq-0054] Can I return a product if it was purchased with a discount code? (score=-3.8403)\n",
      "  3. [faq-0014] What is your price adjustment policy? (score=-3.9959)\n",
      "  4. [faq-0088] Can I request a refund if the price drops after my purchase? (score=-4.2463)\n",
      "  5. [faq-0081] What is your privacy policy? (score=-6.1638)\n"
     ]
    }
   ],
   "source": [
    "# Demo 1: Retrieval only\n",
    "print(\"\\n=== Retrieval-Only ===\")\n",
    "for q in [\n",
    "    \"How do I reset my password?\",\n",
    "    \"Do you offer international shipping?\",\n",
    "    \"What is your refund policy?\",\n",
    "]:\n",
    "    print(\"\\nQ:\", q)\n",
    "    results = query_without_llm(index, bm25, corpus_items, q)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"  {i}. [{r['doc_id']}] {r['question']} (score={r['score']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
